2022-09-17 14:55:24 Hail: INFO: Running Hail version 0.2.99-57537fea08d4
2022-09-17 14:55:25 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-09-17 14:55:25 root: ERROR: UnsupportedFileSystemException: No FileSystem for scheme "gs"
From org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme "gs"
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3281)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3301)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:479)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at is.hail.io.fs.HadoopFS.fileStatus(HadoopFS.scala:166)
	at is.hail.io.fs.FS.isDir(FS.scala:364)
	at is.hail.io.fs.FS.isDir$(FS.scala:362)
	at is.hail.io.fs.HadoopFS.isDir(HadoopFS.scala:72)
	at is.hail.expr.ir.RelationalSpec$.readMetadata(AbstractMatrixTableSpec.scala:31)
	at is.hail.expr.ir.RelationalSpec$.readReferences(AbstractMatrixTableSpec.scala:74)
	at is.hail.variant.ReferenceGenome$.fromHailDataset(ReferenceGenome.scala:581)
	at is.hail.variant.ReferenceGenome.fromHailDataset(ReferenceGenome.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



2022-09-17 14:56:07 root: ERROR: UnsupportedFileSystemException: No FileSystem for scheme "gs"
From org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme "gs"
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3281)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3301)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:479)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at is.hail.io.fs.HadoopFS.fileStatus(HadoopFS.scala:166)
	at is.hail.io.fs.FS.isDir(FS.scala:364)
	at is.hail.io.fs.FS.isDir$(FS.scala:362)
	at is.hail.io.fs.HadoopFS.isDir(HadoopFS.scala:72)
	at is.hail.expr.ir.RelationalSpec$.readMetadata(AbstractMatrixTableSpec.scala:31)
	at is.hail.expr.ir.RelationalSpec$.readReferences(AbstractMatrixTableSpec.scala:74)
	at is.hail.variant.ReferenceGenome$.fromHailDataset(ReferenceGenome.scala:581)
	at is.hail.variant.ReferenceGenome.fromHailDataset(ReferenceGenome.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.base/java.lang.Thread.run(Thread.java:829)



2022-09-17 14:56:36 SparkContext: INFO: Invoking stop() from shutdown hook
2022-09-17 14:56:36 AbstractConnector: INFO: Stopped Spark@79b56e74{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-09-17 14:56:36 SparkUI: INFO: Stopped Spark web UI at http://192.168.0.181:4040
2022-09-17 14:56:36 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-09-17 14:56:36 JavaUtils: WARN: Attempt to delete using native Unix OS command failed for path = /private/var/folders/x1/7112ysln0nl2vyr99j1nllf40000gp/T/blockmgr-1169cc13-0f97-4312-bffd-f25fc7511111. Falling back to Java IO way
java.io.IOException: Failed to delete: /private/var/folders/x1/7112ysln0nl2vyr99j1nllf40000gp/T/blockmgr-1169cc13-0f97-4312-bffd-f25fc7511111
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:163)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1141)
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:182)
	at org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:178)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:178)
	at org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:173)
	at org.apache.spark.storage.BlockManager.stop(BlockManager.scala:1931)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:92)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2108)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1419)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2108)
	at org.apache.spark.SparkContext.$anonfun$new$37(SparkContext.scala:661)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1996)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.io.IOException: Cannot run program "rm": error=0, Failed to exec spawn helper.
	at java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1128)
	at java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1071)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:159)
	... 30 more
Caused by: java.io.IOException: error=0, Failed to exec spawn helper.
	at java.base/java.lang.ProcessImpl.forkAndExec(Native Method)
	at java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:340)
	at java.base/java.lang.ProcessImpl.start(ProcessImpl.java:271)
	at java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1107)
	... 32 more
2022-09-17 14:56:36 MemoryStore: INFO: MemoryStore cleared
2022-09-17 14:56:36 BlockManager: INFO: BlockManager stopped
2022-09-17 14:56:36 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-09-17 14:56:36 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-09-17 14:56:36 SparkContext: INFO: Successfully stopped SparkContext
2022-09-17 14:56:36 ShutdownHookManager: INFO: Shutdown hook called
2022-09-17 14:56:36 ShutdownHookManager: INFO: Deleting directory /private/var/folders/x1/7112ysln0nl2vyr99j1nllf40000gp/T/spark-75eb7e22-1f8d-4ff4-b6bc-f331f7b3a424/pyspark-6a272180-159c-4fd4-8c0b-d398ed890350
2022-09-17 14:56:36 ShutdownHookManager: INFO: Deleting directory /private/var/folders/x1/7112ysln0nl2vyr99j1nllf40000gp/T/spark-75eb7e22-1f8d-4ff4-b6bc-f331f7b3a424
2022-09-17 14:56:36 ShutdownHookManager: INFO: Deleting directory /private/var/folders/x1/7112ysln0nl2vyr99j1nllf40000gp/T/spark-635afdd4-d34e-408c-aead-fc9f5a864de7
